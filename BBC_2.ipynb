{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BBC 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaRYLh6Byl1spuRGeEyr6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korayaslaan/artificial_intelligence/blob/main/BBC_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_ZJWyQULxBn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import bs4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "import re\n",
        "import urllib3\n",
        "from pandas import DataFrame\n",
        "import csv\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import csv\n",
        "import concurrent\n",
        "import multiprocessing\n",
        "from multiprocessing import pool\n",
        "import io\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getWeb(i):\n",
        "  r = requests.get(i) \n",
        "  soup = BeautifulSoup(r.content, 'html5lib')\n",
        "  status = soup.find(\"h1\").getText()\n",
        "  array = []\n",
        "  count = 0\n",
        "  degisken = \"\"\n",
        "  sentence = re.sub(\"^\\s+|\\s+$\", \"\", status, flags=re.UNICODE)\n",
        "  kontrol = sentence[0]+sentence[1]+sentence[2]\n",
        "  if(kontrol != \"404\"):\n",
        "    with open(\"Deneme.txt\", 'a') as file: \n",
        "      file.write(i+'\\n')#sayfaya gidiyo içinde veri varsa linki alacak.404 gelirse devam edecek "
      ],
      "metadata": {
        "id": "2m_ipwCoL5jl"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.bbc.com/news/technology-\"\n",
        "for i in range(58000000,59999999):#burda gözlemlediğim 50000000 sayısından başlıyo ama çok seyrek haberler\n",
        "    link = \"{}{}\".format(url,i)\n",
        "    with open(\"Deneme.txt\", 'a') as file: #dosyada internetimle alakalı olabilir buradan oluşturamadım \n",
        "        file.write(link+'\\n')             #jupyter notebooktan oluşturup buraya yükledim"
      ],
      "metadata": {
        "id": "Db3e-ZRunc41"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"LinkAllDeneme.txt\",'r',newline='') as f:\n",
        "  for i in f.readlines():    \n",
        "     getWeb(i)"
      ],
      "metadata": {
        "id": "kKSFMIO8L5eJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}