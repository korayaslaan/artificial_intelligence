{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewYorkTimes Content.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnG8hWO720IunwN2uOL9yQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korayaslaan/artificial_intelligence/blob/main/NewYorkTimes_Content.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "jT9EaNAM8FMC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import bs4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "import re\n",
        "import urllib3\n",
        "from pandas import DataFrame\n",
        "import csv\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import csv\n",
        "import concurrent\n",
        "import multiprocessing\n",
        "from multiprocessing import pool\n",
        "import io\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def creator(url):\n",
        "    r = requests.get(url)   \n",
        "    soup = BeautifulSoup(r.content, 'html5lib')\n",
        "    title = soup.find(\"h1\").getText()\n",
        "    # print(title)\n",
        "    content = \"\"\n",
        "    for wrapper in soup.find_all('div', {\"class\":\"css-1mweozg\"}):\n",
        "      content = content + wrapper.text\n",
        "    # print(content)\n",
        "    try:\n",
        "      category = soup.find(\"a\", attrs = {\"class\":\"css-nuvmzp\"}).getText()\n",
        "    except:\n",
        "      try:\n",
        "        category = soup.find(\"div\", attrs = {\"class\":\"e1vbbbt70\"}).getText()\n",
        "      except:\n",
        "        category = \"Null\"\n",
        "    # print(category)\n",
        "    try:\n",
        "      date = soup.find(\"time\", attrs = {\"class\":\"e16638kd0\"}).getText()\n",
        "      date = date.replace(\",\",\"\")\n",
        "      date = datetime.strptime(date,\"%B %d %Y\").strftime(\"%Y-%m-%d\")\n",
        "    except:\n",
        "      date = soup.find(\"time\", attrs = {\"class\":\"e16638kd0\"}).getText()\n",
        "      date = date.replace(\",\",\"\")\n",
        "      date = date.replace(\".\",\"\")\n",
        "      date = datetime.strptime(date,\"%b %d %Y\").strftime(\"%Y-%m-%d\")\n",
        "    # print(date)\n",
        "    w_data=\"{};{};{};{};{}\".format(url,date,category,title,content)\n",
        "    # print(url)\n",
        "    # print(w_data)\n",
        "    with open(\"NewYorkTimesContent2.txt\", 'a') as file: \n",
        "       file.write(w_data+'\\n')\n",
        "       file.close()\n",
        "      \n"
      ],
      "metadata": {
        "id": "CZYOajU78Pgs"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creator(\"https://www.nytimes.com/1983/10/14/business/information-science-inc-reports-earnings-for-qtr-to-july-31.html?searchResultPosition=1\")"
      ],
      "metadata": {
        "id": "toae0QOP8pJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinksNews=[]\n",
        "with open(\"Nytimes.txt\",'r',newline='') as f:\n",
        "  for i in f.readlines():    \n",
        "    LinksNews.append(i)\n",
        "\n",
        "t1=time.time()\n",
        "with concurrent.futures.ProcessPoolExecutor() as execut:\n",
        "  b_res=[execut.submit(creator,i.strip()) for i in LinksNews]\n",
        "\n",
        "print(time.time()-t1)\n"
      ],
      "metadata": {
        "id": "NsfUP4Ef8Pbo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}